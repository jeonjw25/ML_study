{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swin-Transformer_CustomVer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRDbnCw1/GsnPLuOUBX68M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonjw25/ML_study/blob/main/Swin_Transformer_CustomVer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nvhz3kssGTr"
      },
      "source": [
        "# Step 1: Swin-Transformer git clone\n",
        "[Microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer/blob/main/get_started.md)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwO4mmboDELD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a616bc4-3260-4035-cce1-368eaf2aa25a"
      },
      "source": [
        "!git clone https://github.com/microsoft/Swin-Transformer.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Swin-Transformer'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 141 (delta 64), reused 105 (delta 53), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (141/141), 953.61 KiB | 4.89 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74bMt3stDEt3",
        "outputId": "cca0c88f-8766-45ae-d190-db18b7b25832"
      },
      "source": [
        "%cd Swin-Transformer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Swin-Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs_jakASsa2z"
      },
      "source": [
        "# Step 2: 요구하는 버전의 torch, cuda 다운"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ-noK9AFLN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5410a6e-171f-4771-95ea-f3cb71604d54"
      },
      "source": [
        "!python -m pip install torch==1.7.1 torchvision==0.8.2 cudatoolkit==10.1 -f https://download.pytorch.org/whl/torch_stable.html "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1\n",
            "  Downloading https://download.pytorch.org/whl/rocm3.8/torch-1.7.1%2Brocm3.8-cp37-cp37m-linux_x86_64.whl (588.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.0 MB 24 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.8.2%2Bcu92-cp37-cp37m-linux_x86_64.whl (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 226 kB/s \n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cudatoolkit==10.1 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for cudatoolkit==10.1\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX4RFcxCs4rE",
        "outputId": "247a96bb-b39a-47a3-9e5c-689ba0e435a0"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version:1.9.0+cu102\n",
            "cuda version: 10.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_tFwZucs7Yt"
      },
      "source": [
        "# Step 3: 필요 library 다운\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CQii_-DIjc7"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okCVC0HxNI9V"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvUqoFUrNJT2"
      },
      "source": [
        "!pip install opencv-python==4.4.0.46 termcolor==1.1.0 yacs==0.1.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d64XD32toB4"
      },
      "source": [
        "!pip install -U PyYAML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz7wAUZxtuZo",
        "outputId": "704a4e76-5b6a-4c34-e6a9-e69ca023b73c"
      },
      "source": [
        "import torch\n",
        "import timm\n",
        "print(torch.__version__)\n",
        "print(timm.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n",
            "0.4.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHoZ4LqruMXK"
      },
      "source": [
        "# Step 4: Google Mount\n",
        "(생략가능)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pniCHw-lZ5QR",
        "outputId": "088d8406-e752-4bab-9941-3e648600c643"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p65d8i3fuRlD"
      },
      "source": [
        "# Step 5: Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDcfAWtBuXKL"
      },
      "source": [
        "## Step 5-1: config file 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvjQboLcsfYh",
        "outputId": "f5e4124c-129c-4ef2-b600-287318eb40b7"
      },
      "source": [
        "!ls configs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Swin-Transformer\n",
            "swin_base_patch4_window12_384.yaml\n",
            "swin_base_patch4_window7_224.yaml\n",
            "swin_large_patch4_window12_384.yaml\n",
            "swin_large_patch4_window7_224.yaml\n",
            "swin_mlp_base_patch4_window7_224.yaml\n",
            "swin_mlp_tiny_c12_patch4_window8_256.yaml\n",
            "swin_mlp_tiny_c24_patch4_window8_256.yaml\n",
            "swin_mlp_tiny_c6_patch4_window8_256.yaml\n",
            "swin_small_patch4_window7_224.yaml\n",
            "swin_tiny_c24_patch4_window8_256.yaml\n",
            "swin_tiny_patch4_window7_224.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlwMpNUdNJeN"
      },
      "source": [
        "#!python -m torch.distributed.launch --nproc_per_node 1 --master_port 12345 main.py --eval \\\n",
        "#--cfg configs/swin_base_patch4_window7_224.yaml --resume swin_base_patch4_window7_224.pth --data-path ../drive/MyDrive/images/dog.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK2SNoRKNJli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e34f09-328c-4649-ca4d-a7a4b65b4a7f"
      },
      "source": [
        "import collections.abc as container_abcs\n",
        "!python -m torch.distributed.launch --nproc_per_node 1  --master_port 12345  main.py \\\n",
        "--cfg configs/swin_tiny_patch4_window7_224.yaml --data-path ../drive/MyDrive/love_data --batch-size 128 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:164: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  \"The module torch.distributed.launch is deprecated \"\n",
            "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
            "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
            " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
            "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
            "  entrypoint       : main.py\n",
            "  min_nodes        : 1\n",
            "  max_nodes        : 1\n",
            "  nproc_per_node   : 1\n",
            "  run_id           : none\n",
            "  rdzv_backend     : static\n",
            "  rdzv_endpoint    : 127.0.0.1:29500\n",
            "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
            "  max_restarts     : 3\n",
            "  monitor_interval : 5\n",
            "  log_dir          : None\n",
            "  metrics_cfg      : {}\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_uc1fczap/none_at68c7ke\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=0\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_uc1fczap/none_at68c7ke/attempt_0/0/error.json\n",
            "=> merge config from configs/swin_tiny_patch4_window7_224.yaml\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 302, in <module>\n",
            "    assert amp is not None, \"amp not installed!\"\n",
            "AssertionError: amp not installed!\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 686) of binary: /usr/bin/python3\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 3/3 attempts left; will restart worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=1\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_uc1fczap/none_at68c7ke/attempt_1/0/error.json\n",
            "=> merge config from configs/swin_tiny_patch4_window7_224.yaml\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 302, in <module>\n",
            "    assert amp is not None, \"amp not installed!\"\n",
            "AssertionError: amp not installed!\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 690) of binary: /usr/bin/python3\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 2/3 attempts left; will restart worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=2\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_uc1fczap/none_at68c7ke/attempt_2/0/error.json\n",
            "=> merge config from configs/swin_tiny_patch4_window7_224.yaml\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 302, in <module>\n",
            "    assert amp is not None, \"amp not installed!\"\n",
            "AssertionError: amp not installed!\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 696) of binary: /usr/bin/python3\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 1/3 attempts left; will restart worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=3\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_uc1fczap/none_at68c7ke/attempt_3/0/error.json\n",
            "=> merge config from configs/swin_tiny_patch4_window7_224.yaml\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 302, in <module>\n",
            "    assert amp is not None, \"amp not installed!\"\n",
            "AssertionError: amp not installed!\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 700) of binary: /usr/bin/python3\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (FAILED). Waiting 300 seconds for other agents to finish\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0004665851593017578 seconds\n",
            "{\"name\": \"torchelastic.worker.status.FAILED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"700\", \"role\": \"default\", \"hostname\": \"37db76000a2d\", \"state\": \"FAILED\", \"total_run_time\": 20, \"rdzv_backend\": \"static\", \"raw_error\": \"{\\\"message\\\": \\\"<NONE>\\\"}\", \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [1]}\", \"agent_restarts\": 3}}\n",
            "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"37db76000a2d\", \"state\": \"SUCCEEDED\", \"total_run_time\": 20, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3\\\"}\", \"agent_restarts\": 3}}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py:354: UserWarning: \n",
            "\n",
            "**********************************************************************\n",
            "               CHILD PROCESS FAILED WITH NO ERROR_FILE                \n",
            "**********************************************************************\n",
            "CHILD PROCESS FAILED WITH NO ERROR_FILE\n",
            "Child process 700 (local_rank 0) FAILED (exitcode 1)\n",
            "Error msg: Process failed with exitcode 1\n",
            "Without writing an error file to <N/A>.\n",
            "While this DOES NOT affect the correctness of your application,\n",
            "no trace information about the error will be available for inspection.\n",
            "Consider decorating your top level entrypoint function with\n",
            "torch.distributed.elastic.multiprocessing.errors.record. Example:\n",
            "\n",
            "  from torch.distributed.elastic.multiprocessing.errors import record\n",
            "\n",
            "  @record\n",
            "  def trainer_main(args):\n",
            "     # do train\n",
            "**********************************************************************\n",
            "  warnings.warn(_no_error_file_warning_msg(rank, failure))\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 173, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 169, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 624, in run\n",
            "    )(*cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 116, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 247, in launch_agent\n",
            "    failures=result.failures,\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "***************************************\n",
            "             main.py FAILED            \n",
            "=======================================\n",
            "Root Cause:\n",
            "[0]:\n",
            "  time: 2021-09-14_05:44:44\n",
            "  rank: 0 (local_rank: 0)\n",
            "  exitcode: 1 (pid: 700)\n",
            "  error_file: <N/A>\n",
            "  msg: \"Process failed with exitcode 1\"\n",
            "=======================================\n",
            "Other Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "***************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbuMEjAfNJsi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFcZ7UujNJy0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLWaeCcINJ_1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
